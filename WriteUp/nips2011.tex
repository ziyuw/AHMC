\documentclass{article} % For LaTeX2e
\usepackage{nips11submit_e,times}
%\documentstyle[nips10submit_09,times,art10]{article} % For LaTeX 2.09

% Math notation from Kevin's style file.
\include{mydef}

\usepackage{graphicx} 

% For citations
%\usepackage{natbib}

% For algorithms
\usepackage{algorithm}
\usepackage{algorithmic}

\newcommand{\vectornorm}[1]{\left|\left|#1\right|\right|}
\def\sigman{\sigma}
\newcommand{\SSR}{\mbox{SSR}}
\newcommand{\murf}{\mu_{\mathtt{rf}}}
\newcommand{\sigrf}{\sigma^2_{\mathtt{rf}}}
\newcommand{\eirf}{EI_{\mathtt{rf}}}
\newcommand{\func}{(\cdot)}
\newcommand{\tree}{\mathcal{T}}
\newcommand{\fmap}{\widehat{\mathbf{f}}}
\newcommand{\vxstar}{\mathbf{x}^{\star}}
\newcommand{\vxbest}{\mathbf{x}^{+}}
\newcommand\TT{\rule{0pt}{2.6ex}}
\newcommand\BB{\rule[-1.2ex]{0pt}{0pt}}
\newcommand{\FIM}{{\bf J}}
\DeclareMathOperator*{\argmax}{argmax}
\DeclareMathOperator*{\argmin}{argmin}
\newcommand{\sfrac}[2]{\leavevmode\kern.1em
           \raise.5ex\hbox{\footnotesize #1}\kern-.1em
                   /\kern-.15em\lower.25ex\hbox{\footnotesize #2}}
\def\mnote#1{\marginpar{\tiny #1}}
\def\rmnote#1{\reversemarginpar{\tiny #1}}
\def\capstyle#1{\small \emph{#1}}

\title{Adaptive Hybrid Monte Carlo with Contextual Bandits}


\author{
David S.~Hippocampus\thanks{ Use footnote for providing further information
about author (webpage, alternative address)---\emph{not} for acknowledging
funding agencies.} \\
Department of Computer Science\\
Cranberry-Lemon University\\
Pittsburgh, PA 15213 \\
\texttt{hippo@cs.cranberry-lemon.edu} \\
\And
Coauthor \\
Affiliation \\
Address \\
\texttt{email} \\
\AND
Coauthor \\
Affiliation \\
Address \\
\texttt{email} \\
\And
Coauthor \\
Affiliation \\
Address \\
\texttt{email} \\
\And
Coauthor \\
Affiliation \\
Address \\
\texttt{email} \\
(if needed)\\
}

% The \author macro works with any number of authors. There are two commands
% used to separate the names and addresses of multiple authors: \And and \AND.
%
% Using \And between authors leaves it to \LaTeX{} to determine where to break
% the lines. Using \AND forces a linebreak at that point. So, if \LaTeX{}
% puts 3 of 4 authors names on the first line, and the last on the second
% line, try using \AND instead of \And before the third author name.

\newcommand{\fix}{\marginpar{FIX}}
\newcommand{\new}{\marginpar{NEW}}

%\nipsfinalcopy % Uncomment for camera-ready version

\begin{document}


\maketitle

\begin{abstract}
This paper introduces a novel way of adapting the Hybrid Monte Carlo (HMC) algorithm using Bayesian optimization. 
HMC is a very popular and widely used Markov chain Monte Carlo (MCMC) method, but it requires careful tuning of its hyper-parameters. We propose a parametric Bayesian optimization technique to carry out the adaptation of the hyper-parameters while the Markov chain runs. We show that this adaptation technique can be mapped to the problem of contextual bandits with nonlinear features, which is known to have bounded regret. This bound ensures that we meet the asymptotic vanishing adaptation requirement of adaptive MCMC methods. The paper also proposes the use of cross-validation error measures for adaptation, which we believe are more pragmatic than many existing adaptation objectives. The new measures take the intended use of the model, whose parameters are estimated by HMC, into consideration. We show on several datasets that the adaptive algorithm can tune HMC automatically and that it often does better than human experts.
\end{abstract}

\input{introduction}
% Neal's adapting without adaptation

% Organisation of the paper potentially

\input{hybridmc}


\input{adaptiveHMC}
\subsection{Choices of Rewards}
There is much work on the optimal acceptance rate of the HMC algorithm. In \cite{beskos2010optimal}, Beskos et al. showed rigorously that under the assumption that $\exp(-H)$ consist of $d >> 1$ i.i.d. components we have the acceptance to be around $0.651$. An optimal acceptance rate of 0.65 has been shown by Neal in \cite{neal2010mcmc} by approximation. Many similar works suggests similar values \cite{creutz1988global} \cite{sexton1992hamiltonian} \cite{kennedy1991acceptances}. Chen et al. stated that their experiments suggested the optimal acceptance ratio is around 0.7 \cite{chen2001exploring}. Therefore it is possible to tune $\epsilon$ and $L$ based on acceptence rate.



\input{experiments}

\small{
\bibliography{refs, adaptsaw,thesis,mc, bandits}{}
\bibliographystyle{plain}
}

\end{document}
